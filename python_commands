#creating a list using for loop and range function
lst = list(x for x in range(10))
#if the format is list-like, even if you have to provide a single value, use [].
#renaming columns
passing it to df.columns = ['renamed_of_new_column1', 'renamed_of_new_column2']
#deleting column
del df['column name']
#reording columns
df_reordered = df_original[['list_of_reordered_columns']]
#printing entire data frame
print(df.to_string())
#slicing, replacing,stripping strings in individual series or column from dataframe
country = energy['Country'].str.replace(' \(', '(') ## \ is used as escape character. 
country = energy['Country'].str.split('(').str.get(0)
country = energy['Country'].str.strip('characters_to_strip_without_comma_just_write') ## Stripping the string by giving charactes.
#.strip will strip any permutation of strings that you give, until it hits a character out of the given list. 

#slicing using re.split #Used in coursera, course #1, Assignment 4
import re
re.split(' \(+', 'Words (words, words.')[0] #Have to pass each row individually, not on column
###re.split info and illustations:
#format:
re.split(pattern, string[, maxsplit=0])
Explanation:
Split string by the occurrences of pattern. If capturing parentheses are used in pattern, then the text of all groups 
in the pattern are also returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits occur, 
and the remainder of the string is returned as the final element of the list.
Illustations:
1. Code for column in data frame #This is twice as fast if tow functions are used per above method. (first replace and then split)
>>> import re
>>> vector = []
>>> for row in df.RegionName:
>>>   row = re.split(' \(+', row)[0]
>>>   vector.append(row)
    
>>> re.split('\W+', 'Words, words, words.')
['Words', 'words', 'words', '']
>>> re.split('(\W+)', 'Words, words, words.')
['Words', ', ', 'words', ', ', 'words', '.', '']
>>> re.split('\W+', 'Words, words, words.', 1)
['Words', 'words, words.']
#setting, replacing index
df.set_index('Index', drop = True, inplace=True)
df1 = df.reset_index(drop = True)

#Using map(), filter(), reduce() in python 3.0
>>>def f(x): return x % 2 != 0 and x % 3 != 0
#filter
>>> list(filter(f, range(2, 25)))
[5, 7, 11, 13, 17, 19, 23]
>>> def cube(x): return x*x*x
#map
>>> list(map(cube, range(1, 11)))
[1, 8, 27, 64, 125, 216, 343, 512, 729, 1000]
#reduce
>>> import functools
>>> def add(x,y): return x+y
...
>>> functools.reduce(add, range(1, 11))

#Getting index using Boolean mask of a data frame, follwing commands gives list
index = df[df['% Renewable'] == max].index.tolist()

#Getting index using Boolean mask of a series, follwing commands gives list
series[series == 'element_of_which_index_is_needed'].index[0]

###Always assign a copy of data frame if you want to process it unless you want to change original. If you assign original to new variable 
and change that variable, the original also gets changed, unless the copy has made while assigning it to new variable. 
new_variable_data_frame = old_variable_data_frame.copy()


###There is a difference between type 'numpy.float64' and just 'float'. It may matter depending on the output requirement. 

#Iterative code to read a line from text file in raw format: (Refer documentation for 'f.readlines(filesize = int--(in bytes, optional)' if following method does not suit the purpose)
>>> f = open('university_towns.txt')
>>> for line in f:
>>>   output = repr(line)  # The repr() of a string adds string quotes and backslashes:
>>>   print(output)

#Getting an index of an item in the dataframe:
index = df.index(item)

#Getting average(mean) of several columns in a data frame:
df['avg'] = df[['Monday', 'Tuesday']].mean(axis=1)

#getting a key of a dictionary
mydict.keys()[mydict.values().index(value)]
mydict.keys()[mydict.values().index(16)]
#getting a value of a dictionary
dict.get(key, default=None)

#Using dictionary to map values of a dataframe column
df['new_column_name'] = df['column_which_needs_to_be_mapped_has_the_entries_similar_to_the_dictionary_keys'].map(dictionary_name)

##Querying data frame, getting a row of a dataframe:
df['Column_name'].iloc[row_number] #for getting a specific item
#entire row of all columns:
df.iloc[['row_number']]
OR TRY THIS - q4_1.T[['row_number']].T
##getting list of all the items in that row:
print(list(q4_1.iloc['row_number']))

#Getting diagonal elements of a numpy array: (Assuming array has shape 3X3 like this:)
>>> x = np.array([[1, 2, 3], [4, 5, 6]]
>>> x.reshape(9)[::4]

### For grouping columns through multi-inidex with each row in index on3 (level 0) shows all of the releted rows in second index (level 1), 
first sort the first index (level 0) alphabetically -- then and then only all level 1 entries related to specific level 0 would be 
in a single row. 
# Function for sorting a list alphabetically:
>>> sorted(list_name/column_name_in_dataframe)


### Sorting a particular column and re-arranging rows in a data frame:
df_sorted = df_copy.sort('column_name_to_sortwise').reset_index(drop = True) #along with resetting index, if required. Dont forget to make 
a copy. Its safer that way!

### Sorting through multiple columns in dataframe:
>>> df = df.sort_values(['Device', 'Timestamp'], ascending=[True, False])

#Getting index in mulitiindex:
>>> df.index.get_level_values(0)
>>> index.get_level_values('second')

#inserting a thousand separator(comma) (,) in a number 
>>> '{:,}'.format(1234567890)
### For common string operators refer the link: https://docs.python.org/3/library/string.html#format-specification-mini-language

### If data frame has word(label) index then getting an for getting integer index for that label index:
df.index.get_loc('label_index_name')

# Replacing a value in dataframe:
df.replace(to_replace='item_to_replace', value='replacement_value', inplace=True/False)

##Timeit magic function:
>> %%timeit -n 10

##Getting unique values out of very very large series: (if unique does not work, this will work)-- Tested on 73000 element array:
unique_values = set(data_frame.column_name)
**You may want ot convert it back into list. Simply converty using list() function**

Creating Data frame from dictionary:
A) Method 1:
1. Create a dictionary.
2. Append it to a list.
3. Pass that row into dataframe. >>pd.DataFrame(row_list).

B) Method 2:
df = pd.DataFrame()
>>> data = pd.DataFrame({"A": range(3)})
>>> df.append(data)

but the append doesn't happen in-place, so you'll have to store the output if you want it:

>>> df = df.append(data)
>>> df
   A
0  0
1  1
2  2

Notes: Method 1 is faster. Reason: Every time you call append, Pandas returns a copy of the original dataframe plus your new row. 
This is called quadratic copy, and it is an O(N^2) operation that will quickly become very slow (especially since you have lots of data).

Proof:
>> %%timeit -n 100
>> rec_brk = pd.DataFrame()
>> for year in list(set(temp_min.Year)):
>>     dict1 = {'Min Broken': len(temp_min[temp_min.Year == year]), 'Year': year, 'Max Broken': len(temp_max[temp_max.Year == year])}
>>     rec_brk = rec_brk.append(dict1, ignore_index = True)
[Output] 100 loops, best of 3: 41.1 ms per loop


>> %%timeit -n 100
>> rows_list= []
>> for year in list(set(temp_min.Year)):
>>     dict1 = {'Min Broken': len(temp_min[temp_min.Year == year]), 'Year': year, 'Max Broken': len(temp_max[temp_max.Year == year])}
>>     rows_list.append(dict1)
>> rec_brk = pd.DataFrame(rows_list)
[Output] 100 loops, best of 3: 19.4 ms per loop

**Sorting through groupy and multiple columns (Link):
http://stackoverflow.com/questions/14941366/pandas-sort-by-group-aggregate-and-column

#Drop Duplicates rowwise in a particular column:
new_df = old_df.drop_duplicates(['column_name'], keep = 'last')

## Getting array of locations where the condition is true:
>>> array_name = np.where(condition)
[output]: array of elemetns of locations where the condition is true.

## Append,Extend, and '+':
1. Append:
>>> c = [1, 2, 3]
>>> c.append(c)
>>> c
[Out]: [1, 2, 3, [...]]

2. Extend and '+':
>>> c=[1,2,3]
>>> c.extend(c)
>>> c
[1, 2, 3, 1, 2, 3]

3. Fastest way to create and append to a list (one million elements):
>>> lst = list(range(10000000))
>>> for i in range(1,10000000):
>>>    lst[i] = i

4. Mod in Python: % -- Gives reminder of integer division
>>> 15% 4
[Out]: 3

# Converting an entire column of a dataframe from dates into Dates Format (inputs series (tested for dtype Object), outputs series):
>> series_name = pd.to_datetime(df.column_name, format="%m/%d/%y %H:%M")

# Converting a single string into datetime:
>> datetime.strptime('Aug 16 2015', '%b %d %Y')
please refer https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior for formatting details.

# Converting current time to timestamp(seconds) - epoch format:
>> datetime.datetime.today().timestamp()

# Getting a weekday of a date (here its assumed the date is not formated):
>> datetime.datetime.strptime('January 11, 2010', '%B %d, %Y').strftime('%A')

*** strptime translates to 
"parse (convert) string to datetime object."

strftime translates to 
"create formatted string for given time/date/datetime object according to specified format." ***


# Getting only month in a new column from a dataframe column using apply, and lambda functins.
>> df['Month'] = df.Date.apply(lambda x: x.month) 

# Getting a month in a new column, day in a single tuple from a dataframe column using apply, and lambda functins. 
>> data_df['Year'], data_df['Month-Day'] = zip(*data_df['Date'].apply(lambda x: (x.year,(x.month, x.day))))

# Subsetting the data frame by giving list of values in the condition:
suppose the list of values we are interested in is:
>> lst = ['STREET', 'PARKING LOT/GARAGE(NON.RESID.)', 'ALLEY','GAS STATION','DRIVEWAY - RESIDENTIAL' ]
>> Subsetted_dataset = df[df.column_name.isin(lst)]

# Converting data from oject(string) of a column to float:
>> df['rtmin'] = df['rtmin'].astype(str).astype(float)
### First convert object to string and then to float.

#Python String Formatting and escape characters link:
https://www.tutorialspoint.com/python/python_strings.htm
e.g. 
>>> tail = "My name is %s and weight is %d kg!" % ('Zara', 21)

#Link for reading a file frequently (particularly log files):
https://stackoverflow.com/questions/5419888/reading-from-a-frequently-updated-file

#If open() gives some decoding error, use encoder.
>>> op = open('pi_json.json',encoding='utf8')

# If JSONDecoder error occures in json or json.load() or json.loads(), make sure each quote is proper ". Copy paste and see minute details if the two quotes are same. 
# If Json.dumps(list_of_dictionaries) is giving an error 'Object of type 'int64' is not JSON serializable', use 'default=str' parameter:
>>> json.dumps(list_of_dics,default=str)
Link for further research and main problem behind the error: (The int may be numpy.int64, it should be python int), refer the link:
https://stackoverflow.com/questions/11942364/typeerror-integer-is-not-json-serializable-when-serializing-json-in-python
# Converting data types link:
https://stackoverflow.com/questions/9452775/converting-numpy-dtypes-to-native-python-types

# SQL Decimal conversion link:
https://docs.microsoft.com/en-us/sql/t-sql/data-types/decimal-and-numeric-transact-sql

# Taking a value associated with a variable:
>>> eval('variable_name')
eg. 
>>> mgroups = ['df1','quake']
>>>     for group in mgroups:
               for row in eval(group).T:
               ...
               ...
 In the above programme eval(group).T will be df1.T and quake.T where df1 and quake are the dataframe stored previously. 
 Refer iPython notebook- PI_df_to_json_pi (1) in Google Drive> __PI_REST for implementation illustration. 

# Creating cron jobs at specified minutes, reference links to get started:
1. https://stackoverflow.com/questions/16094545/cron-job-every-5-minutes-starting-from-a-specific-time
2. https://unix.stackexchange.com/questions/239964/create-cron-jobs-to-repeat-every-x-units-of-time-starting-on-an-arbitary-unit

# Converting unix timestamp from seconds to datetime format:
>>> datetime.datetime.fromtimestamp(int("timestamp_to_convert")).strftime('%Y-%m-%d %H:%M:%S')

# Creating a python file for importing into another script:
** Create empty file using notepad ++ first. Then copy and paste your code in windows plain notepad. Dont use notepad ++ for copying, 
after importing the imported file/module will throw lot of errors. Mostly due to indentation. 

#Getting working directory in python:
>>> import os
>>> os.getcwd()

# Getting list of files and directories in the current working directoy:
>>> import os
>>> os.listdire(os.curdir)

# Chnaging the current working directoy in python:
>>> import os
>>> os.chdir('/path/to/change')

# Using exec and eval to make a value of a variable a variable: (Execute and understand the following code)
>>> lst=['strvar1', 'strvar2', 'strvar3']
>>> for key in lst:
>>> a = pd.DataFrame()
>>> exec(key + "= a")
>>> print(key, eval(key))

# Beutiful Soup finding all tags in BS object:
>>> [tag.name for tag in soup_object.find_all()]

#Using constant in map:
>>> from operator import add
>>> from itertools import repeat
>>> list(map(add, [1,2,3], repeat(4)))
>>> list(map(add, [1,2,3], repeat(4)))

#Selecting certain columns/rows out of all available columns in pandas:

X = df.iloc[:,:-1]
y = df.iloc[:,-1]

#this will select all rows with all columns except  the last one in X and last one in y. (Example from Coursera ML Assignment-3, Q2).

#Using zip to send multiple arguments to map Execute the following cod eand understand what its doing:
>>> a = [1,2,3]
>>> b = [4,5,6]
>>> def addi(tups):
>>>    y = tups[0]
>>>    z = tups[1]
>>>    print(y+z)
>>>    return 
>>> s = map(addi, zip(a,b))
>>> list(s)

#Getting a key from a value of a dictionary in python 3:
>>> mydict = {'george':16,'amber':19}
>>> print(list(mydict.keys())[list(mydict.values()).index(16)]) # Prints george


in python 2.7:
>>> mydict = {'george':16,'amber':19}
>>> print mydict.keys()[mydict.values().index(16)] # Prints george

#Finding difference between two strings:
>>> s1 = 'HELPMEPLZ'
>>> s2 = 'HELPNEPLX'
>>> [i for i in xrange(len(s1)) if s1[i] != s2[i]]

#Adding a column to a dataframe with different length (more elements than length of df index)
>>> dic_for_df = {0: {0: 0, 1: 1, 2: 2},
 1: {0: ' first name0', 1: ' first name1', 2: ' first name2'},
 2: {0: ' last name0', 1: ' last name1', 2: None},
 3: {0: 0, 1: 1, 2: 2},
 4: {0: ' first name0', 1: ' first name1', 2: ' first name2'},
 5: {0: ' last name0', 1: ' last name1', 2: None},
 'new': {0: 1, 1: 2, 2: 3}}  #define a dictionary to form df for illustartion
>>> dfc = pd.DataFrame(dic_for_df)       #form a df
>>> new_col=pd.Series([1,2,3,4,5])       #define a new column that you want to add to df
>>> new_col_dic = new_col.to_dict()      #convert that series into dict
>>> dic = dfc.to_dict()                  #make a dictionary of your df
>>> dic['6'] = new_col_dic               #add your new column dictionary to your df dictionary
>>> finally_solved = pd.DataFrame(dic)   #form a dataframe from the updated dictionary
>>> dfc1 = dfc.copy()                    #to illustrate the difference between above (dictionary) method and direct assignment when length of new assigned column is greater than length of dataframe index
>>> dfc1['new_col'] = new_col            #execute the code and see the difference between dfc1 dataframe and finally_solved dataframe

#Note: if length of new column is less than length of index if dataframe, then you may assign directly, Na values will be populated automatically based on missing index in new series; no need to go by dictionary method

#Storing output of linux command into variable and processing it using regular expression:
#Use case here: Getting the character set of the text file in linux using "file" command. 
#file command syntax for linux is: $file -bi <file_name>
#Code-
>>> import subprocess
>>> result=subprocess.run(['file','-bi','Uninstall_IBMStreams4.2.0.0_Summary.0.log'], stdout=subprocess.PIPE)
>>> a=str(result.stdout)
>>> a
"b'text/plain; charset=us-ascii\\n'"
>>> re.findall('[\S\s]*charset=([\S]*)\\\\n',a)  #refer https://docs.python.org/2/howto/regex.html for catching backslashes '\\' in pyhton re
['us-ascii']

